{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alIIEHibGc3M"
   },
   "source": [
    "## Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "6eDUJ4NtGc3P",
    "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>...</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
       "0   41       Yes      Travel_Rarely                   Sales                 1   \n",
       "1   49        No  Travel_Frequently  Research & Development                 8   \n",
       "2   37       Yes      Travel_Rarely  Research & Development                 2   \n",
       "3   33        No  Travel_Frequently  Research & Development                 3   \n",
       "4   27        No      Travel_Rarely  Research & Development                 2   \n",
       "\n",
       "   Education EducationField  EnvironmentSatisfaction  HourlyRate  \\\n",
       "0          2  Life Sciences                        2          94   \n",
       "1          1  Life Sciences                        3          61   \n",
       "2          2          Other                        4          92   \n",
       "3          4  Life Sciences                        4          56   \n",
       "4          1        Medical                        1          40   \n",
       "\n",
       "   JobInvolvement  ...  PerformanceRating RelationshipSatisfaction  \\\n",
       "0               3  ...                  3                        1   \n",
       "1               2  ...                  4                        4   \n",
       "2               2  ...                  3                        2   \n",
       "3               3  ...                  3                        3   \n",
       "4               3  ...                  3                        4   \n",
       "\n",
       "   StockOptionLevel TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                 0                 8                      0               1   \n",
       "1                 1                10                      3               3   \n",
       "2                 0                 7                      3               3   \n",
       "3                 0                 8                      3               3   \n",
       "4                 1                 6                      3               3   \n",
       "\n",
       "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0               6                   4                        0   \n",
       "1              10                   7                        1   \n",
       "2               0                   0                        0   \n",
       "3               8                   7                        3   \n",
       "4               2                   2                        2   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     5  \n",
       "1                     7  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "#  Import and read the attrition data\n",
    "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g22aQSY4Gc3Q",
    "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         43\n",
       "Attrition                    2\n",
       "BusinessTravel               3\n",
       "Department                   3\n",
       "DistanceFromHome            29\n",
       "Education                    5\n",
       "EducationField               6\n",
       "EnvironmentSatisfaction      4\n",
       "HourlyRate                  71\n",
       "JobInvolvement               4\n",
       "JobLevel                     5\n",
       "JobRole                      9\n",
       "JobSatisfaction              4\n",
       "MaritalStatus                3\n",
       "NumCompaniesWorked          10\n",
       "OverTime                     2\n",
       "PercentSalaryHike           15\n",
       "PerformanceRating            2\n",
       "RelationshipSatisfaction     4\n",
       "StockOptionLevel             4\n",
       "TotalWorkingYears           40\n",
       "TrainingTimesLastYear        7\n",
       "WorkLifeBalance              4\n",
       "YearsAtCompany              37\n",
       "YearsInCurrentRole          19\n",
       "YearsSinceLastPromotion     16\n",
       "YearsWithCurrManager        18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "attrition_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "50vMgBEnJbfM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attrition\n",
      "No     1233\n",
      "Yes     237\n",
      "Name: count, dtype: int64\n",
      "Department\n",
      "Research & Development    961\n",
      "Sales                     446\n",
      "Human Resources            63\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create y_df with the Attrition and Department columns\n",
    "y_df = attrition_df[['Attrition', 'Department']]\n",
    "print(y_df['Attrition'].value_counts())\n",
    "print(y_df['Department'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Virka0zLGc3R",
    "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         int64\n",
       "BusinessTravel             object\n",
       "HourlyRate                  int64\n",
       "DistanceFromHome            int64\n",
       "Education                   int64\n",
       "EducationField             object\n",
       "NumCompaniesWorked          int64\n",
       "PerformanceRating           int64\n",
       "EnvironmentSatisfaction     int64\n",
       "TotalWorkingYears           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of at least 10 column names to use as X data\n",
    "columns = ['Age', 'BusinessTravel', 'HourlyRate', 'DistanceFromHome', 'Education', 'EducationField', 'NumCompaniesWorked', 'PerformanceRating', 'EnvironmentSatisfaction', 'TotalWorkingYears']\n",
    "\n",
    "\n",
    "# Create X_df using your selected columns\n",
    "X_df = attrition_df[columns]\n",
    "\n",
    "# Show the data types for X_df\n",
    "X_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KaJfdOGUMHMR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BusinessTravel   \n",
      "Travel_Rarely        1043\n",
      "Travel_Frequently     277\n",
      "Non-Travel            150\n",
      "Name: count, dtype: int64\n",
      "EducationField  \n",
      "Life Sciences       606\n",
      "Medical             464\n",
      "Marketing           159\n",
      "Technical Degree    132\n",
      "Other                82\n",
      "Human Resources      27\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, random_state=78)\n",
    "\n",
    "print(X_df[['BusinessTravel']].value_counts())\n",
    "print(X_df[['EducationField']].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYubUJqiLCSp",
    "outputId": "53f31721-571c-4c94-d13e-25a715749593"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/m_btl88n5hs7w95j59p7v2180000gn/T/ipykernel_97556/808158197.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train['BusinessTravel'] = X_train['BusinessTravel'].replace({'Non-Travel': 1, 'Travel_Rarely': 2, 'Travel_Frequently': 3})\n",
      "/var/folders/0g/m_btl88n5hs7w95j59p7v2180000gn/T/ipykernel_97556/808158197.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train['EducationField'] = X_train['EducationField'].replace({'Life Sciences': 1, 'Medical': 2, 'Marketing': 3, 'Technical Degree': 4, 'Human Resources': 5, 'Other': 6})\n"
     ]
    }
   ],
   "source": [
    "# Convert your X data to numeric data types however you see fit\n",
    "# Add new code cells as necessary\n",
    "\n",
    "X_train['BusinessTravel'] = X_train['BusinessTravel'].replace({'Non-Travel': 1, 'Travel_Rarely': 2, 'Travel_Frequently': 3})\n",
    "X_train['EducationField'] = X_train['EducationField'].replace({'Life Sciences': 1, 'Medical': 2, 'Marketing': 3, 'Technical Degree': 4, 'Human Resources': 5, 'Other': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EWA-aIA5Gc3T"
   },
   "outputs": [],
   "source": [
    "# Create a StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler to the training data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the training and testing data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_encoded_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder for the Department column\n",
    "department_encoder = OneHotEncoder(sparse_output=False)\n",
    "department_encoded_train = department_encoder.fit_transform(y_train[['Department']])\n",
    "\n",
    "# Create a OneHotEncoder for the Attrition column\n",
    "attrition_encoder = OneHotEncoder(sparse_output=False)\n",
    "attrition_encoded_train = attrition_encoder.fit_transform(y_train[['Attrition']])\n",
    "\n",
    "# Apply each encoder to training and testing data\n",
    "department_encoded_train = department_encoder.transform(y_train[['Department']])\n",
    "department_encoded_test = department_encoder.transform(y_test[['Department']])\n",
    "\n",
    "attrition_encoded_train = attrition_encoder.transform(y_train[['Attrition']])\n",
    "attrition_encoded_test = attrition_encoder.transform(y_test[['Attrition']])\n",
    "\n",
    "attrition_encoded_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykNmu_WWGc3T"
   },
   "source": [
    "## Create, Compile, and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "WUptZqmSGc3T"
   },
   "outputs": [],
   "source": [
    "# Find the number of columns in the X training data\n",
    "X_columns_qty = X_train_scaled.shape[1]\n",
    "\n",
    "# Create the input layer\n",
    "input_layer = layers.Input(shape=(X_columns_qty,), name='input')\n",
    "\n",
    "# Create at least two shared layers\n",
    "shared_layer1 = layers.Dense(units=32, activation='relu', name='shared1')(input_layer)\n",
    "shared_layer2 = layers.Dense(units=32, activation='relu', name='shared2')(shared_layer1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "JukjTm2yTEqd"
   },
   "outputs": [],
   "source": [
    "# Create a branch for Department\n",
    "# with a hidden layer and an output layer\n",
    "department_branch = layers.Dense(units=64, activation='relu', name='department_branch')(shared_layer2)\n",
    "# Create the hidden layer\n",
    "department_branch = layers.Dense(units=32, activation='relu', name='department_hidden')(department_branch)\n",
    "\n",
    "# Create the output layer\n",
    "department_output = layers.Dense(units=3, activation='softmax', name='department_output')(department_branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "9OqhUiOJUBkR"
   },
   "outputs": [],
   "source": [
    "# Create a branch for Attrition\n",
    "# with a hidden layer and an output layer\n",
    "attrition_branch = layers.Dense(units=64, activation='relu', name='attrition_branch')(shared_layer2)\n",
    "# Create the hidden layer\n",
    "attrition_branch = layers.Dense(units=32, activation='relu', name='attrition_hidden')(attrition_branch)\n",
    "\n",
    "# Create the output layer\n",
    "attrition_output = layers.Dense(units=2, activation='sigmoid', name='attrition_output')(attrition_branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twmuejdxGc3T",
    "outputId": "25096308-b68b-42e4-e4ea-ae82e97c435a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " shared1 (Dense)                (None, 32)           352         ['input[0][0]']                  \n",
      "                                                                                                  \n",
      " shared2 (Dense)                (None, 32)           1056        ['shared1[0][0]']                \n",
      "                                                                                                  \n",
      " department_branch (Dense)      (None, 64)           2112        ['shared2[0][0]']                \n",
      "                                                                                                  \n",
      " attrition_branch (Dense)       (None, 64)           2112        ['shared2[0][0]']                \n",
      "                                                                                                  \n",
      " department_hidden (Dense)      (None, 32)           2080        ['department_branch[0][0]']      \n",
      "                                                                                                  \n",
      " attrition_hidden (Dense)       (None, 32)           2080        ['attrition_branch[0][0]']       \n",
      "                                                                                                  \n",
      " department_output (Dense)      (None, 3)            99          ['department_hidden[0][0]']      \n",
      "                                                                                                  \n",
      " attrition_output (Dense)       (None, 2)            66          ['attrition_hidden[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,957\n",
      "Trainable params: 9,957\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[department_output, attrition_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'department_output': 'categorical_crossentropy', 'attrition_output': 'categorical_crossentropy'},\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8oGy0dpGc3U",
    "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "35/35 - 0s - loss: 1.5443 - department_output_loss: 0.9940 - attrition_output_loss: 0.5503 - department_output_accuracy: 0.5236 - attrition_output_accuracy: 0.7976 - 356ms/epoch - 10ms/step\n",
      "Epoch 2/100\n",
      "35/35 - 0s - loss: 1.2243 - department_output_loss: 0.7743 - attrition_output_loss: 0.4500 - department_output_accuracy: 0.6661 - attrition_output_accuracy: 0.8276 - 35ms/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "35/35 - 0s - loss: 1.1826 - department_output_loss: 0.7499 - attrition_output_loss: 0.4327 - department_output_accuracy: 0.6661 - attrition_output_accuracy: 0.8276 - 26ms/epoch - 757us/step\n",
      "Epoch 4/100\n",
      "35/35 - 0s - loss: 1.1609 - department_output_loss: 0.7397 - attrition_output_loss: 0.4212 - department_output_accuracy: 0.6661 - attrition_output_accuracy: 0.8276 - 33ms/epoch - 946us/step\n",
      "Epoch 5/100\n",
      "35/35 - 0s - loss: 1.1420 - department_output_loss: 0.7306 - attrition_output_loss: 0.4113 - department_output_accuracy: 0.6652 - attrition_output_accuracy: 0.8294 - 32ms/epoch - 911us/step\n",
      "Epoch 6/100\n",
      "35/35 - 0s - loss: 1.1281 - department_output_loss: 0.7197 - attrition_output_loss: 0.4084 - department_output_accuracy: 0.6688 - attrition_output_accuracy: 0.8330 - 32ms/epoch - 913us/step\n",
      "Epoch 7/100\n",
      "35/35 - 0s - loss: 1.1058 - department_output_loss: 0.7109 - attrition_output_loss: 0.3949 - department_output_accuracy: 0.6851 - attrition_output_accuracy: 0.8403 - 33ms/epoch - 949us/step\n",
      "Epoch 8/100\n",
      "35/35 - 0s - loss: 1.0858 - department_output_loss: 0.6968 - attrition_output_loss: 0.3889 - department_output_accuracy: 0.6915 - attrition_output_accuracy: 0.8448 - 33ms/epoch - 946us/step\n",
      "Epoch 9/100\n",
      "35/35 - 0s - loss: 1.0628 - department_output_loss: 0.6849 - attrition_output_loss: 0.3779 - department_output_accuracy: 0.6942 - attrition_output_accuracy: 0.8494 - 34ms/epoch - 966us/step\n",
      "Epoch 10/100\n",
      "35/35 - 0s - loss: 1.0490 - department_output_loss: 0.6773 - attrition_output_loss: 0.3718 - department_output_accuracy: 0.7051 - attrition_output_accuracy: 0.8457 - 34ms/epoch - 961us/step\n",
      "Epoch 11/100\n",
      "35/35 - 0s - loss: 1.0310 - department_output_loss: 0.6638 - attrition_output_loss: 0.3672 - department_output_accuracy: 0.7142 - attrition_output_accuracy: 0.8530 - 33ms/epoch - 935us/step\n",
      "Epoch 12/100\n",
      "35/35 - 0s - loss: 1.0138 - department_output_loss: 0.6561 - attrition_output_loss: 0.3577 - department_output_accuracy: 0.7214 - attrition_output_accuracy: 0.8593 - 33ms/epoch - 948us/step\n",
      "Epoch 13/100\n",
      "35/35 - 0s - loss: 0.9973 - department_output_loss: 0.6445 - attrition_output_loss: 0.3528 - department_output_accuracy: 0.7278 - attrition_output_accuracy: 0.8621 - 33ms/epoch - 954us/step\n",
      "Epoch 14/100\n",
      "35/35 - 0s - loss: 0.9831 - department_output_loss: 0.6371 - attrition_output_loss: 0.3459 - department_output_accuracy: 0.7377 - attrition_output_accuracy: 0.8621 - 34ms/epoch - 959us/step\n",
      "Epoch 15/100\n",
      "35/35 - 0s - loss: 0.9657 - department_output_loss: 0.6261 - attrition_output_loss: 0.3396 - department_output_accuracy: 0.7423 - attrition_output_accuracy: 0.8711 - 32ms/epoch - 917us/step\n",
      "Epoch 16/100\n",
      "35/35 - 0s - loss: 0.9527 - department_output_loss: 0.6202 - attrition_output_loss: 0.3325 - department_output_accuracy: 0.7423 - attrition_output_accuracy: 0.8702 - 33ms/epoch - 950us/step\n",
      "Epoch 17/100\n",
      "35/35 - 0s - loss: 0.9331 - department_output_loss: 0.6088 - attrition_output_loss: 0.3243 - department_output_accuracy: 0.7486 - attrition_output_accuracy: 0.8693 - 33ms/epoch - 957us/step\n",
      "Epoch 18/100\n",
      "35/35 - 0s - loss: 0.9237 - department_output_loss: 0.6012 - attrition_output_loss: 0.3225 - department_output_accuracy: 0.7568 - attrition_output_accuracy: 0.8757 - 32ms/epoch - 919us/step\n",
      "Epoch 19/100\n",
      "35/35 - 0s - loss: 0.9022 - department_output_loss: 0.5908 - attrition_output_loss: 0.3113 - department_output_accuracy: 0.7559 - attrition_output_accuracy: 0.8793 - 33ms/epoch - 939us/step\n",
      "Epoch 20/100\n",
      "35/35 - 0s - loss: 0.8904 - department_output_loss: 0.5850 - attrition_output_loss: 0.3054 - department_output_accuracy: 0.7595 - attrition_output_accuracy: 0.8820 - 33ms/epoch - 932us/step\n",
      "Epoch 21/100\n",
      "35/35 - 0s - loss: 0.8699 - department_output_loss: 0.5747 - attrition_output_loss: 0.2952 - department_output_accuracy: 0.7604 - attrition_output_accuracy: 0.8811 - 34ms/epoch - 985us/step\n",
      "Epoch 22/100\n",
      "35/35 - 0s - loss: 0.8616 - department_output_loss: 0.5705 - attrition_output_loss: 0.2911 - department_output_accuracy: 0.7704 - attrition_output_accuracy: 0.8857 - 34ms/epoch - 963us/step\n",
      "Epoch 23/100\n",
      "35/35 - 0s - loss: 0.8406 - department_output_loss: 0.5554 - attrition_output_loss: 0.2852 - department_output_accuracy: 0.7759 - attrition_output_accuracy: 0.8848 - 33ms/epoch - 956us/step\n",
      "Epoch 24/100\n",
      "35/35 - 0s - loss: 0.8287 - department_output_loss: 0.5526 - attrition_output_loss: 0.2761 - department_output_accuracy: 0.7677 - attrition_output_accuracy: 0.8920 - 33ms/epoch - 957us/step\n",
      "Epoch 25/100\n",
      "35/35 - 0s - loss: 0.8144 - department_output_loss: 0.5474 - attrition_output_loss: 0.2669 - department_output_accuracy: 0.7695 - attrition_output_accuracy: 0.8929 - 33ms/epoch - 939us/step\n",
      "Epoch 26/100\n",
      "35/35 - 0s - loss: 0.8091 - department_output_loss: 0.5446 - attrition_output_loss: 0.2645 - department_output_accuracy: 0.7704 - attrition_output_accuracy: 0.8929 - 35ms/epoch - 992us/step\n",
      "Epoch 27/100\n",
      "35/35 - 0s - loss: 0.7877 - department_output_loss: 0.5371 - attrition_output_loss: 0.2506 - department_output_accuracy: 0.7759 - attrition_output_accuracy: 0.9065 - 39ms/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "35/35 - 0s - loss: 0.7648 - department_output_loss: 0.5176 - attrition_output_loss: 0.2472 - department_output_accuracy: 0.7877 - attrition_output_accuracy: 0.9056 - 36ms/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "35/35 - 0s - loss: 0.7481 - department_output_loss: 0.5081 - attrition_output_loss: 0.2400 - department_output_accuracy: 0.7895 - attrition_output_accuracy: 0.9138 - 33ms/epoch - 932us/step\n",
      "Epoch 30/100\n",
      "35/35 - 0s - loss: 0.7305 - department_output_loss: 0.5032 - attrition_output_loss: 0.2273 - department_output_accuracy: 0.8113 - attrition_output_accuracy: 0.9147 - 33ms/epoch - 954us/step\n",
      "Epoch 31/100\n",
      "35/35 - 0s - loss: 0.7091 - department_output_loss: 0.4870 - attrition_output_loss: 0.2221 - department_output_accuracy: 0.7931 - attrition_output_accuracy: 0.9229 - 33ms/epoch - 937us/step\n",
      "Epoch 32/100\n",
      "35/35 - 0s - loss: 0.7066 - department_output_loss: 0.4888 - attrition_output_loss: 0.2177 - department_output_accuracy: 0.8031 - attrition_output_accuracy: 0.9229 - 33ms/epoch - 931us/step\n",
      "Epoch 33/100\n",
      "35/35 - 0s - loss: 0.6803 - department_output_loss: 0.4758 - attrition_output_loss: 0.2045 - department_output_accuracy: 0.8067 - attrition_output_accuracy: 0.9265 - 34ms/epoch - 982us/step\n",
      "Epoch 34/100\n",
      "35/35 - 0s - loss: 0.6712 - department_output_loss: 0.4711 - attrition_output_loss: 0.2001 - department_output_accuracy: 0.8158 - attrition_output_accuracy: 0.9183 - 33ms/epoch - 946us/step\n",
      "Epoch 35/100\n",
      "35/35 - 0s - loss: 0.6581 - department_output_loss: 0.4604 - attrition_output_loss: 0.1977 - department_output_accuracy: 0.8212 - attrition_output_accuracy: 0.9283 - 33ms/epoch - 934us/step\n",
      "Epoch 36/100\n",
      "35/35 - 0s - loss: 0.6342 - department_output_loss: 0.4496 - attrition_output_loss: 0.1846 - department_output_accuracy: 0.8176 - attrition_output_accuracy: 0.9347 - 33ms/epoch - 946us/step\n",
      "Epoch 37/100\n",
      "35/35 - 0s - loss: 0.6337 - department_output_loss: 0.4524 - attrition_output_loss: 0.1813 - department_output_accuracy: 0.8258 - attrition_output_accuracy: 0.9338 - 34ms/epoch - 970us/step\n",
      "Epoch 38/100\n",
      "35/35 - 0s - loss: 0.6054 - department_output_loss: 0.4354 - attrition_output_loss: 0.1700 - department_output_accuracy: 0.8267 - attrition_output_accuracy: 0.9401 - 33ms/epoch - 956us/step\n",
      "Epoch 39/100\n",
      "35/35 - 0s - loss: 0.5952 - department_output_loss: 0.4222 - attrition_output_loss: 0.1731 - department_output_accuracy: 0.8358 - attrition_output_accuracy: 0.9328 - 34ms/epoch - 968us/step\n",
      "Epoch 40/100\n",
      "35/35 - 0s - loss: 0.5881 - department_output_loss: 0.4201 - attrition_output_loss: 0.1680 - department_output_accuracy: 0.8385 - attrition_output_accuracy: 0.9365 - 34ms/epoch - 964us/step\n",
      "Epoch 41/100\n",
      "35/35 - 0s - loss: 0.5634 - department_output_loss: 0.4100 - attrition_output_loss: 0.1535 - department_output_accuracy: 0.8367 - attrition_output_accuracy: 0.9456 - 38ms/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "35/35 - 0s - loss: 0.5532 - department_output_loss: 0.3996 - attrition_output_loss: 0.1536 - department_output_accuracy: 0.8448 - attrition_output_accuracy: 0.9465 - 88ms/epoch - 3ms/step\n",
      "Epoch 43/100\n",
      "35/35 - 0s - loss: 0.5282 - department_output_loss: 0.3837 - attrition_output_loss: 0.1445 - department_output_accuracy: 0.8548 - attrition_output_accuracy: 0.9474 - 39ms/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "35/35 - 0s - loss: 0.5149 - department_output_loss: 0.3800 - attrition_output_loss: 0.1349 - department_output_accuracy: 0.8612 - attrition_output_accuracy: 0.9528 - 39ms/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "35/35 - 0s - loss: 0.5120 - department_output_loss: 0.3773 - attrition_output_loss: 0.1347 - department_output_accuracy: 0.8566 - attrition_output_accuracy: 0.9483 - 39ms/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "35/35 - 0s - loss: 0.4822 - department_output_loss: 0.3605 - attrition_output_loss: 0.1217 - department_output_accuracy: 0.8657 - attrition_output_accuracy: 0.9601 - 40ms/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "35/35 - 0s - loss: 0.4698 - department_output_loss: 0.3506 - attrition_output_loss: 0.1192 - department_output_accuracy: 0.8621 - attrition_output_accuracy: 0.9601 - 37ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "35/35 - 0s - loss: 0.4528 - department_output_loss: 0.3426 - attrition_output_loss: 0.1101 - department_output_accuracy: 0.8648 - attrition_output_accuracy: 0.9646 - 39ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "35/35 - 0s - loss: 0.4460 - department_output_loss: 0.3377 - attrition_output_loss: 0.1082 - department_output_accuracy: 0.8702 - attrition_output_accuracy: 0.9628 - 41ms/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "35/35 - 0s - loss: 0.4317 - department_output_loss: 0.3287 - attrition_output_loss: 0.1031 - department_output_accuracy: 0.8793 - attrition_output_accuracy: 0.9710 - 37ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "35/35 - 0s - loss: 0.4150 - department_output_loss: 0.3161 - attrition_output_loss: 0.0989 - department_output_accuracy: 0.8829 - attrition_output_accuracy: 0.9655 - 40ms/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "35/35 - 0s - loss: 0.4078 - department_output_loss: 0.3134 - attrition_output_loss: 0.0943 - department_output_accuracy: 0.8793 - attrition_output_accuracy: 0.9691 - 99ms/epoch - 3ms/step\n",
      "Epoch 53/100\n",
      "35/35 - 0s - loss: 0.3977 - department_output_loss: 0.2997 - attrition_output_loss: 0.0980 - department_output_accuracy: 0.8929 - attrition_output_accuracy: 0.9682 - 39ms/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "35/35 - 0s - loss: 0.3870 - department_output_loss: 0.2968 - attrition_output_loss: 0.0902 - department_output_accuracy: 0.8902 - attrition_output_accuracy: 0.9737 - 39ms/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "35/35 - 0s - loss: 0.3767 - department_output_loss: 0.2894 - attrition_output_loss: 0.0873 - department_output_accuracy: 0.8929 - attrition_output_accuracy: 0.9719 - 33ms/epoch - 957us/step\n",
      "Epoch 56/100\n",
      "35/35 - 0s - loss: 0.3740 - department_output_loss: 0.2896 - attrition_output_loss: 0.0844 - department_output_accuracy: 0.9002 - attrition_output_accuracy: 0.9764 - 32ms/epoch - 917us/step\n",
      "Epoch 57/100\n",
      "35/35 - 0s - loss: 0.3496 - department_output_loss: 0.2794 - attrition_output_loss: 0.0702 - department_output_accuracy: 0.8902 - attrition_output_accuracy: 0.9791 - 33ms/epoch - 932us/step\n",
      "Epoch 58/100\n",
      "35/35 - 0s - loss: 0.3417 - department_output_loss: 0.2722 - attrition_output_loss: 0.0695 - department_output_accuracy: 0.9047 - attrition_output_accuracy: 0.9819 - 33ms/epoch - 936us/step\n",
      "Epoch 59/100\n",
      "35/35 - 0s - loss: 0.3225 - department_output_loss: 0.2552 - attrition_output_loss: 0.0673 - department_output_accuracy: 0.9102 - attrition_output_accuracy: 0.9800 - 34ms/epoch - 972us/step\n",
      "Epoch 60/100\n",
      "35/35 - 0s - loss: 0.3180 - department_output_loss: 0.2526 - attrition_output_loss: 0.0654 - department_output_accuracy: 0.9056 - attrition_output_accuracy: 0.9809 - 33ms/epoch - 940us/step\n",
      "Epoch 61/100\n",
      "35/35 - 0s - loss: 0.3178 - department_output_loss: 0.2487 - attrition_output_loss: 0.0691 - department_output_accuracy: 0.9129 - attrition_output_accuracy: 0.9800 - 33ms/epoch - 943us/step\n",
      "Epoch 62/100\n",
      "35/35 - 0s - loss: 0.3130 - department_output_loss: 0.2438 - attrition_output_loss: 0.0693 - department_output_accuracy: 0.9156 - attrition_output_accuracy: 0.9764 - 34ms/epoch - 964us/step\n",
      "Epoch 63/100\n",
      "35/35 - 0s - loss: 0.2882 - department_output_loss: 0.2303 - attrition_output_loss: 0.0579 - department_output_accuracy: 0.9201 - attrition_output_accuracy: 0.9837 - 33ms/epoch - 935us/step\n",
      "Epoch 64/100\n",
      "35/35 - 0s - loss: 0.2744 - department_output_loss: 0.2216 - attrition_output_loss: 0.0528 - department_output_accuracy: 0.9229 - attrition_output_accuracy: 0.9864 - 32ms/epoch - 921us/step\n",
      "Epoch 65/100\n",
      "35/35 - 0s - loss: 0.2753 - department_output_loss: 0.2209 - attrition_output_loss: 0.0545 - department_output_accuracy: 0.9292 - attrition_output_accuracy: 0.9891 - 32ms/epoch - 921us/step\n",
      "Epoch 66/100\n",
      "35/35 - 0s - loss: 0.2712 - department_output_loss: 0.2221 - attrition_output_loss: 0.0492 - department_output_accuracy: 0.9220 - attrition_output_accuracy: 0.9873 - 33ms/epoch - 934us/step\n",
      "Epoch 67/100\n",
      "35/35 - 0s - loss: 0.2517 - department_output_loss: 0.2058 - attrition_output_loss: 0.0459 - department_output_accuracy: 0.9301 - attrition_output_accuracy: 0.9882 - 32ms/epoch - 924us/step\n",
      "Epoch 68/100\n",
      "35/35 - 0s - loss: 0.2441 - department_output_loss: 0.2018 - attrition_output_loss: 0.0424 - department_output_accuracy: 0.9319 - attrition_output_accuracy: 0.9909 - 33ms/epoch - 948us/step\n",
      "Epoch 69/100\n",
      "35/35 - 0s - loss: 0.2354 - department_output_loss: 0.1958 - attrition_output_loss: 0.0396 - department_output_accuracy: 0.9410 - attrition_output_accuracy: 0.9918 - 32ms/epoch - 908us/step\n",
      "Epoch 70/100\n",
      "35/35 - 0s - loss: 0.2217 - department_output_loss: 0.1838 - attrition_output_loss: 0.0379 - department_output_accuracy: 0.9456 - attrition_output_accuracy: 0.9936 - 31ms/epoch - 900us/step\n",
      "Epoch 71/100\n",
      "35/35 - 0s - loss: 0.2149 - department_output_loss: 0.1789 - attrition_output_loss: 0.0360 - department_output_accuracy: 0.9419 - attrition_output_accuracy: 0.9927 - 31ms/epoch - 899us/step\n",
      "Epoch 72/100\n",
      "35/35 - 0s - loss: 0.2126 - department_output_loss: 0.1784 - attrition_output_loss: 0.0342 - department_output_accuracy: 0.9474 - attrition_output_accuracy: 0.9927 - 32ms/epoch - 922us/step\n",
      "Epoch 73/100\n",
      "35/35 - 0s - loss: 0.1961 - department_output_loss: 0.1632 - attrition_output_loss: 0.0329 - department_output_accuracy: 0.9537 - attrition_output_accuracy: 0.9936 - 33ms/epoch - 938us/step\n",
      "Epoch 74/100\n",
      "35/35 - 0s - loss: 0.1921 - department_output_loss: 0.1617 - attrition_output_loss: 0.0304 - department_output_accuracy: 0.9546 - attrition_output_accuracy: 0.9927 - 32ms/epoch - 913us/step\n",
      "Epoch 75/100\n",
      "35/35 - 0s - loss: 0.1828 - department_output_loss: 0.1522 - attrition_output_loss: 0.0306 - department_output_accuracy: 0.9574 - attrition_output_accuracy: 0.9918 - 32ms/epoch - 910us/step\n",
      "Epoch 76/100\n",
      "35/35 - 0s - loss: 0.1835 - department_output_loss: 0.1545 - attrition_output_loss: 0.0289 - department_output_accuracy: 0.9483 - attrition_output_accuracy: 0.9936 - 32ms/epoch - 917us/step\n",
      "Epoch 77/100\n",
      "35/35 - 0s - loss: 0.1857 - department_output_loss: 0.1578 - attrition_output_loss: 0.0279 - department_output_accuracy: 0.9492 - attrition_output_accuracy: 0.9936 - 33ms/epoch - 931us/step\n",
      "Epoch 78/100\n",
      "35/35 - 0s - loss: 0.1775 - department_output_loss: 0.1477 - attrition_output_loss: 0.0299 - department_output_accuracy: 0.9528 - attrition_output_accuracy: 0.9936 - 32ms/epoch - 908us/step\n",
      "Epoch 79/100\n",
      "35/35 - 0s - loss: 0.1795 - department_output_loss: 0.1519 - attrition_output_loss: 0.0275 - department_output_accuracy: 0.9483 - attrition_output_accuracy: 0.9936 - 77ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "35/35 - 0s - loss: 0.1678 - department_output_loss: 0.1375 - attrition_output_loss: 0.0304 - department_output_accuracy: 0.9691 - attrition_output_accuracy: 0.9891 - 38ms/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "35/35 - 0s - loss: 0.1554 - department_output_loss: 0.1292 - attrition_output_loss: 0.0262 - department_output_accuracy: 0.9701 - attrition_output_accuracy: 0.9936 - 35ms/epoch - 989us/step\n",
      "Epoch 82/100\n",
      "35/35 - 0s - loss: 0.1526 - department_output_loss: 0.1290 - attrition_output_loss: 0.0236 - department_output_accuracy: 0.9646 - attrition_output_accuracy: 0.9936 - 32ms/epoch - 920us/step\n",
      "Epoch 83/100\n",
      "35/35 - 0s - loss: 0.1616 - department_output_loss: 0.1400 - attrition_output_loss: 0.0217 - department_output_accuracy: 0.9574 - attrition_output_accuracy: 0.9955 - 33ms/epoch - 949us/step\n",
      "Epoch 84/100\n",
      "35/35 - 0s - loss: 0.1428 - department_output_loss: 0.1166 - attrition_output_loss: 0.0262 - department_output_accuracy: 0.9746 - attrition_output_accuracy: 0.9973 - 32ms/epoch - 922us/step\n",
      "Epoch 85/100\n",
      "35/35 - 0s - loss: 0.1269 - department_output_loss: 0.1067 - attrition_output_loss: 0.0202 - department_output_accuracy: 0.9773 - attrition_output_accuracy: 0.9955 - 31ms/epoch - 896us/step\n",
      "Epoch 86/100\n",
      "35/35 - 0s - loss: 0.1250 - department_output_loss: 0.1067 - attrition_output_loss: 0.0183 - department_output_accuracy: 0.9746 - attrition_output_accuracy: 0.9973 - 32ms/epoch - 917us/step\n",
      "Epoch 87/100\n",
      "35/35 - 0s - loss: 0.1269 - department_output_loss: 0.1037 - attrition_output_loss: 0.0231 - department_output_accuracy: 0.9755 - attrition_output_accuracy: 0.9927 - 32ms/epoch - 901us/step\n",
      "Epoch 88/100\n",
      "35/35 - 0s - loss: 0.1283 - department_output_loss: 0.1058 - attrition_output_loss: 0.0225 - department_output_accuracy: 0.9710 - attrition_output_accuracy: 0.9936 - 32ms/epoch - 903us/step\n",
      "Epoch 89/100\n",
      "35/35 - 0s - loss: 0.1356 - department_output_loss: 0.1152 - attrition_output_loss: 0.0204 - department_output_accuracy: 0.9737 - attrition_output_accuracy: 0.9927 - 31ms/epoch - 884us/step\n",
      "Epoch 90/100\n",
      "35/35 - 0s - loss: 0.1284 - department_output_loss: 0.1032 - attrition_output_loss: 0.0252 - department_output_accuracy: 0.9737 - attrition_output_accuracy: 0.9946 - 31ms/epoch - 875us/step\n",
      "Epoch 91/100\n",
      "35/35 - 0s - loss: 0.1116 - department_output_loss: 0.0955 - attrition_output_loss: 0.0161 - department_output_accuracy: 0.9764 - attrition_output_accuracy: 0.9973 - 31ms/epoch - 885us/step\n",
      "Epoch 92/100\n",
      "35/35 - 0s - loss: 0.0994 - department_output_loss: 0.0865 - attrition_output_loss: 0.0129 - department_output_accuracy: 0.9828 - attrition_output_accuracy: 0.9955 - 31ms/epoch - 881us/step\n",
      "Epoch 93/100\n",
      "35/35 - 0s - loss: 0.1007 - department_output_loss: 0.0884 - attrition_output_loss: 0.0123 - department_output_accuracy: 0.9782 - attrition_output_accuracy: 0.9991 - 30ms/epoch - 857us/step\n",
      "Epoch 94/100\n",
      "35/35 - 0s - loss: 0.0952 - department_output_loss: 0.0830 - attrition_output_loss: 0.0122 - department_output_accuracy: 0.9791 - attrition_output_accuracy: 0.9982 - 31ms/epoch - 890us/step\n",
      "Epoch 95/100\n",
      "35/35 - 0s - loss: 0.1101 - department_output_loss: 0.0929 - attrition_output_loss: 0.0171 - department_output_accuracy: 0.9791 - attrition_output_accuracy: 0.9964 - 30ms/epoch - 865us/step\n",
      "Epoch 96/100\n",
      "35/35 - 0s - loss: 0.0922 - department_output_loss: 0.0803 - attrition_output_loss: 0.0119 - department_output_accuracy: 0.9819 - attrition_output_accuracy: 0.9982 - 31ms/epoch - 885us/step\n",
      "Epoch 97/100\n",
      "35/35 - 0s - loss: 0.0895 - department_output_loss: 0.0781 - attrition_output_loss: 0.0114 - department_output_accuracy: 0.9809 - attrition_output_accuracy: 0.9982 - 31ms/epoch - 875us/step\n",
      "Epoch 98/100\n",
      "35/35 - 0s - loss: 0.0880 - department_output_loss: 0.0769 - attrition_output_loss: 0.0111 - department_output_accuracy: 0.9791 - attrition_output_accuracy: 0.9982 - 33ms/epoch - 945us/step\n",
      "Epoch 99/100\n",
      "35/35 - 0s - loss: 0.0854 - department_output_loss: 0.0754 - attrition_output_loss: 0.0100 - department_output_accuracy: 0.9855 - attrition_output_accuracy: 0.9982 - 33ms/epoch - 935us/step\n",
      "Epoch 100/100\n",
      "35/35 - 0s - loss: 0.0813 - department_output_loss: 0.0720 - attrition_output_loss: 0.0094 - department_output_accuracy: 0.9873 - attrition_output_accuracy: 0.9982 - 32ms/epoch - 927us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x315fa33d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_scaled,\n",
    "          {'department_output': department_encoded_train, 'attrition_output': attrition_encoded_train},\n",
    "          epochs=100,\n",
    "          shuffle=True,\n",
    "          verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsMoaQlgGc3U",
    "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 - 0s - loss: 1.0540 - department_output_loss: 0.6904 - attrition_output_loss: 0.3636 - department_output_accuracy: 0.6715 - attrition_output_accuracy: 0.8575 - 32ms/epoch - 927us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.053972840309143,\n",
       " 0.69040846824646,\n",
       " 0.36356422305107117,\n",
       " 0.6715063452720642,\n",
       " 0.8575317859649658]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model with the testing data\n",
    "results = model.evaluate(X_train_scaled,\n",
    "    {'department_output': department_encoded_train, 'attrition_output': attrition_encoded_train},\n",
    "    verbose=2)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlCtlHi0Vt54",
    "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department Accuracy: 0.6715063452720642\n",
      "Attrition Accuracy: 0.8575317859649658\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy for both department and attrition\n",
    "print(f\"Department Accuracy: {results[3]}\")\n",
    "print(f\"Attrition Accuracy: {results[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGSyfsZfWOQM"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In the provided space below, briefly answer the following questions.\n",
    "\n",
    "1. Is accuracy the best metric to use on this data? Why or why not?\n",
    "\n",
    "2. What activation functions did you choose for your output layers, and why?\n",
    "\n",
    "3. Can you name a few ways that this model might be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi9SLpFnWvbF"
   },
   "source": [
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. I think is a good measure for the attrition output, not quite for department for being multiclassified, in that case I would consider Weighted F1 Score, Log Loss or Confusion Matrix.\n",
    "2. I used softmax in the department branch because is a multiclass classification output. And since attrition is binary classified I used sigmoid\n",
    "3. Maybe adding more layers or increasing the units per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
